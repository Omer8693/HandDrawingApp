{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a8e00d3",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (2659896851.py, line 7)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[3], line 7\u001b[1;36m\u001b[0m\n\u001b[1;33m    import numpy as np q\u001b[0m\n\u001b[1;37m                       ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "import time\n",
    "import random\n",
    "from collections import defaultdict\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import json\n",
    "import os\n",
    "\n",
    "GESTURE_LABELS = {\n",
    "    \"draw\": \"Only index finger open\",\n",
    "    \"click\": \"Index, middle and thumb open\",\n",
    "    \"eraser_mode\": \"Index and middle finger open\",\n",
    "    \"draw_mode\": \"Index, middle, ring fingers open\",\n",
    "    \"change_theme\": \"All fingers open (simplified)\",\n",
    "    \"adjust_thickness\": \"Only thumb open\",\n",
    "    \"save\": \"Thumb and pinky open\",\n",
    "    \"load\": \"Middle, ring, pinky open\",\n",
    "    \"clear\": \"All fingers closed\"\n",
    "}\n",
    "\n",
    "LIGHTING_CONDITIONS = {\n",
    "    \"bright\": (500, 700),\n",
    "    \"normal\": (200, 300),\n",
    "    \"dim\": (50, 100)\n",
    "}\n",
    "\n",
    "SCREEN_HEIGHT, SCREEN_WIDTH = 480, 640\n",
    "TARGET_COUNT = 5\n",
    "prev_palm_state = None\n",
    "\n",
    "def apply_style(style_name):\n",
    "    \"\"\"Apply Matplotlib style with fallback to default if style is unavailable.\"\"\"\n",
    "    available_styles = plt.style.available\n",
    "    if style_name in available_styles:\n",
    "        plt.style.use(style_name)\n",
    "    else:\n",
    "        print(f\"Style '{style_name}' not available. Falling back to 'default'.\")\n",
    "        plt.style.use('default')\n",
    "\n",
    "def analyze_gesture(landmarks, hand_label):\n",
    "    global prev_palm_state\n",
    "\n",
    "    def is_open(tip, pip): return tip[1] < pip[1]\n",
    "    def get_point(idx): return landmarks[idx]\n",
    "\n",
    "    thumb_open = get_point(4)[1] < get_point(2)[1] - 0.03 * SCREEN_HEIGHT\n",
    "    index_open = is_open(get_point(8), get_point(6))\n",
    "    middle_open = is_open(get_point(12), get_point(10))\n",
    "    ring_open = is_open(get_point(16), get_point(14))\n",
    "    pinky_open = is_open(get_point(20), get_point(18))\n",
    "\n",
    "    wrist = get_point(0)\n",
    "    middle_mcp = get_point(9)\n",
    "    is_palm_facing = wrist[0] < middle_mcp[0] if hand_label == \"Right\" else wrist[0] > middle_mcp[0]\n",
    "    all_fingers_open = all([thumb_open, index_open, middle_open, ring_open, pinky_open])\n",
    "\n",
    "    if index_open and middle_open and not ring_open and not pinky_open and not thumb_open:\n",
    "        prev_palm_state = is_palm_facing\n",
    "        return 'eraser_mode'\n",
    "    if index_open and middle_open and ring_open and not pinky_open and not thumb_open:\n",
    "        prev_palm_state = is_palm_facing\n",
    "        return 'draw_mode'\n",
    "    if all_fingers_open:\n",
    "        prev_palm_state = is_palm_facing\n",
    "        return 'change_theme'\n",
    "    if thumb_open and not index_open and not middle_open and not ring_open and not pinky_open:\n",
    "        prev_palm_state = is_palm_facing\n",
    "        return 'adjust_thickness'\n",
    "    if thumb_open and pinky_open and not index_open and not middle_open and not ring_open:\n",
    "        prev_palm_state = is_palm_facing\n",
    "        return 'save'\n",
    "    if not thumb_open and not index_open and middle_open and ring_open and pinky_open:\n",
    "        prev_palm_state = is_palm_facing\n",
    "        return 'load'\n",
    "    if not any([index_open, middle_open, ring_open, pinky_open, thumb_open]):\n",
    "        prev_palm_state = is_palm_facing\n",
    "        return 'clear'\n",
    "    if index_open and not middle_open and not ring_open and not pinky_open:\n",
    "        prev_palm_state = is_palm_facing\n",
    "        return 'draw'\n",
    "    if index_open and middle_open and not ring_open and not pinky_open and thumb_open:\n",
    "        prev_palm_state = is_palm_facing\n",
    "        return 'click'\n",
    "\n",
    "    prev_palm_state = is_palm_facing\n",
    "    return 'none'\n",
    "\n",
    "# Create screenshots folder\n",
    "SCREENSHOTS_DIR = \"screenshots\"\n",
    "if not os.path.exists(SCREENSHOTS_DIR):\n",
    "    os.makedirs(SCREENSHOTS_DIR)\n",
    "\n",
    "# Setup\n",
    "mp_hands = mp.solutions.hands\n",
    "mp_draw = mp.solutions.drawing_utils\n",
    "hands = mp_hands.Hands(max_num_hands=1, min_detection_confidence=0.7, min_tracking_confidence=0.5)\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "if not cap.isOpened():\n",
    "    print(\"Error: Could not open camera.\")\n",
    "    exit()\n",
    "\n",
    "# Data storage\n",
    "performance_data = {condition: defaultdict(list) for condition in LIGHTING_CONDITIONS}\n",
    "gesture_counts = defaultdict(int)\n",
    "durations = defaultdict(float)\n",
    "fps_per_gesture = defaultdict(list)\n",
    "\n",
    "aborted = False\n",
    "\n",
    "print(\"Gesture Trainer Started - Press SPACE to record, Q to quit.\\n\")\n",
    "\n",
    "for condition in LIGHTING_CONDITIONS:\n",
    "    print(f\"\\n=== Testing under {condition.upper()} lighting ({LIGHTING_CONDITIONS[condition][0]}‚Äì{LIGHTING_CONDITIONS[condition][1]} lux) ===\")\n",
    "    gesture_counts.clear()\n",
    "    durations.clear()\n",
    "    fps_per_gesture.clear()\n",
    "    last_gesture = None\n",
    "    prev_time = time.time()\n",
    "\n",
    "    while True and not aborted:\n",
    "        available = [g for g in GESTURE_LABELS if gesture_counts[g] < TARGET_COUNT and g != last_gesture]\n",
    "        if not available:\n",
    "            break\n",
    "        current_gesture = random.choice(available)\n",
    "        last_gesture = current_gesture\n",
    "        print(f\"\\n‚û°Ô∏è Show gesture: {current_gesture.upper()} ‚Äî {GESTURE_LABELS[current_gesture]}\")\n",
    "        start_time = time.time()\n",
    "\n",
    "        while True:\n",
    "            ret, frame = cap.read()\n",
    "            if not ret:\n",
    "                print(\"Error: Could not read frame.\")\n",
    "                aborted = True\n",
    "                break\n",
    "\n",
    "            frame = cv2.flip(frame, 1)\n",
    "            rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "            results = hands.process(rgb)\n",
    "\n",
    "            # FPS hesapla\n",
    "            current_time = time.time()\n",
    "            fps = 1 / (current_time - prev_time) if (current_time - prev_time) > 0 else 0\n",
    "            prev_time = current_time\n",
    "            fps_per_gesture[current_gesture].append(fps)\n",
    "\n",
    "            # Gesture analiz\n",
    "            gesture = \"No hand\"\n",
    "            if results.multi_hand_landmarks:\n",
    "                hand = results.multi_hand_landmarks[0]\n",
    "                mp_draw.draw_landmarks(frame, hand, mp_hands.HAND_CONNECTIONS)\n",
    "                h, w, _ = frame.shape\n",
    "                lm = [(pt.x * w, pt.y * h) for pt in hand.landmark]\n",
    "                hand_label = results.multi_handedness[0].classification[0].label if results.multi_handedness else \"Right\"\n",
    "                gesture = analyze_gesture(lm, hand_label)\n",
    "\n",
    "            cv2.putText(frame, f\"Lighting: {condition.upper()}\", (10, 30),\n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 200, 0), 2)\n",
    "            cv2.putText(frame, f\"Target: {current_gesture.upper()}\", (10, 70),\n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)\n",
    "            cv2.putText(frame, f\"Detected: {gesture}\", (10, 110),\n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)\n",
    "            cv2.putText(frame, f\"FPS: {fps:.2f}\", (10, 150),\n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, 1, (200, 255, 200), 2)\n",
    "            cv2.putText(frame, f\"Instruction: {GESTURE_LABELS[current_gesture]}\", (10, 190),\n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 255, 255), 2)\n",
    "            cv2.imshow(\"Gesture Trainer\", frame)\n",
    "\n",
    "            key = cv2.waitKey(1) & 0xFF\n",
    "            if key == ord('q'):\n",
    "                aborted = True\n",
    "                break\n",
    "            elif key == ord(' ') and gesture == current_gesture:\n",
    "                response_time = time.time() - start_time\n",
    "                gesture_counts[gesture] += 1\n",
    "                # Save screenshot\n",
    "                screenshot_filename = os.path.join(SCREENSHOTS_DIR, \n",
    "                    f\"gesture_{gesture}_{gesture_counts[gesture]}_{condition}.png\")\n",
    "                cv2.imwrite(screenshot_filename, frame)\n",
    "                print(f\"üì∏ Saved screenshot: {screenshot_filename}\")\n",
    "                durations[gesture] += response_time\n",
    "                performance_data[condition][gesture].append({\n",
    "                    \"sample\": gesture_counts[gesture],\n",
    "                    \"response_time\": response_time,\n",
    "                    \"fps\": fps\n",
    "                })\n",
    "                print(f\"‚úÖ Captured {gesture_counts[gesture]}/{TARGET_COUNT} for {gesture} (‚è± {response_time:.1f}s, FPS: {fps:.2f})\")\n",
    "                break\n",
    "\n",
    "    if aborted:\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "# Save performance data to JSON\n",
    "with open(\"performance_data.json\", \"w\") as f:\n",
    "    json.dump(performance_data, f, indent=4)\n",
    "\n",
    "# Final Summary\n",
    "if aborted:\n",
    "    print(\"\\n‚ö†Ô∏è Test aborted by user.\\n\")\n",
    "else:\n",
    "    print(\"\\n‚úÖ All gesture tests complete.\\n\")\n",
    "\n",
    "print(\"=== GESTURE TEST SUMMARY ===\")\n",
    "for condition in LIGHTING_CONDITIONS:\n",
    "    print(f\"\\n{condition.upper()} Lighting:\")\n",
    "    for g in GESTURE_LABELS:\n",
    "        samples = performance_data[condition][g]\n",
    "        avg_fps = np.mean([s[\"fps\"] for s in samples]) if samples else 0\n",
    "        avg_time = np.mean([s[\"response_time\"] for s in samples]) if samples else 0\n",
    "        print(f\"{g:15} | {len(samples):2d}/5 samples | Avg Time: {avg_time:.1f}s | Avg FPS: {avg_fps:.2f}\")\n",
    "\n",
    "# Plotting Results\n",
    "all_gestures = list(GESTURE_LABELS.keys())\n",
    "\n",
    "# Plot 1: Bar Plot for Average Response Time by Lighting Condition\n",
    "apply_style('seaborn-v0_8')\n",
    "plt.figure(figsize=(12, 6))\n",
    "bar_width = 0.25\n",
    "x = np.arange(len(all_gestures))\n",
    "for i, condition in enumerate(LIGHTING_CONDITIONS):\n",
    "    avg_times = [np.mean([s[\"response_time\"] for s in performance_data[condition][g]]) if performance_data[condition][g] else 0 for g in all_gestures]\n",
    "    plt.bar(x + i * bar_width, avg_times, bar_width, label=condition.capitalize())\n",
    "plt.title(\"Average Response Time by Gesture and Lighting\", fontsize=14)\n",
    "plt.xlabel(\"Gestures\", fontsize=12)\n",
    "plt.ylabel(\"Response Time (s)\", fontsize=12)\n",
    "plt.xticks(x + bar_width, all_gestures, rotation=45, fontsize=10)\n",
    "plt.legend()\n",
    "plt.grid(axis='y', linestyle='--', alpha=0.6)\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"response_time_bar.png\")\n",
    "plt.close()\n",
    "\n",
    "# Plot 2: Pie Chart for Sample Counts per Lighting Condition\n",
    "apply_style('default')\n",
    "plt.figure(figsize=(10, 8))\n",
    "colors = plt.cm.Paired(np.linspace(0, 1, len(LIGHTING_CONDITIONS)))\n",
    "sample_counts = [sum(len(performance_data[condition][g]) for g in all_gestures) for condition in LIGHTING_CONDITIONS]\n",
    "plt.pie(sample_counts, labels=[c.capitalize() for c in LIGHTING_CONDITIONS], colors=colors, autopct='%1.1f%%', startangle=140)\n",
    "plt.title(\"Distribution of Samples by Lighting Condition\", fontsize=14)\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"sample_counts_pie.png\")\n",
    "plt.close()\n",
    "\n",
    "# Plot 3: Stacked Bar Plot for FPS by Gesture and Lighting\n",
    "apply_style('ggplot')\n",
    "plt.figure(figsize=(12, 6))\n",
    "x = np.arange(len(all_gestures))\n",
    "bottom = np.zeros(len(all_gestures))\n",
    "for condition in LIGHTING_CONDITIONS:\n",
    "    avg_fps = [np.mean([s[\"fps\"] for s in performance_data[condition][g]]) if performance_data[condition][g] else 0 for g in all_gestures]\n",
    "    plt.bar(x, avg_fps, bottom=bottom, label=condition.capitalize())\n",
    "    bottom += np.array(avg_fps)\n",
    "plt.title(\"Stacked FPS by Gesture and Lighting\", fontsize=14)\n",
    "plt.xlabel(\"Gestures\", fontsize=12)\n",
    "plt.ylabel(\"FPS\", fontsize=12)\n",
    "plt.xticks(x, all_gestures, rotation=45, fontsize=10)\n",
    "plt.legend()\n",
    "plt.grid(axis='y', linestyle='--', alpha=0.6)\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"fps_stacked_bar.png\")\n",
    "plt.close()\n",
    "\n",
    "# Plot 4: Line Plot for Response Time Trends\n",
    "apply_style('bmh')\n",
    "plt.figure(figsize=(12, 6))\n",
    "for condition in LIGHTING_CONDITIONS:\n",
    "    avg_times = [np.mean([s[\"response_time\"] for s in performance_data[condition][g]]) if performance_data[condition][g] else 0 for g in all_gestures]\n",
    "    plt.plot(all_gestures, avg_times, marker='o', linestyle='-', linewidth=2, label=condition.capitalize())\n",
    "plt.title(\"Response Time Trends by Gesture and Lighting\", fontsize=14)\n",
    "plt.ylabel(\"Response Time (s)\", fontsize=12)\n",
    "plt.grid(True, linestyle='--', alpha=0.6)\n",
    "plt.xticks(rotation=45, fontsize=10)\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"response_time_line.png\")\n",
    "plt.close()  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
